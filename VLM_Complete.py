"""
ĞŸĞĞ›ĞĞĞ¯ VLM Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°
- Ğ’Ğ°Ñˆ Ğ°Ğ½ÑĞ°Ğ¼Ğ±Ğ»ÑŒ (YOLO + RT-DETR) Ğ´Ğ»Ñ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸ Ğ¼ÑƒÑĞ¾Ñ€Ğ°
- Ğ’Ğ°Ñˆ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ ÑÑ†ĞµĞ½ Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ

Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: "There is plastic on the grass"
"""

import sys
sys.path.append('.')
from PIL import Image
from pathlib import Path
import torch

from vlm_annotation.ensemble_detector import EnsembleDetector
from train_scene_classifier import SceneClassifierInference, SCENE_CLASSES


class CompleteVLM:
    """
    VLM Ğ³Ğ´Ğµ Ğ’Ğ¡Ğ¯ CV Ñ‡Ğ°ÑÑ‚ÑŒ - ÑÑ‚Ğ¾ Ğ²Ğ°ÑˆĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸:
    1. ĞĞ½ÑĞ°Ğ¼Ğ±Ğ»ÑŒ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ² Ğ¼ÑƒÑĞ¾Ñ€Ğ°
    2. ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ ÑÑ†ĞµĞ½
    """
    
    def __init__(
        self,
        yolo_path: str,
        detr_path: str,
        detr_processor_path: str,
        scene_classifier_path: str = None,
        conf_threshold: float = 0.5
    ):
        # Ğ’Ğ°Ñˆ Ğ°Ğ½ÑĞ°Ğ¼Ğ±Ğ»ÑŒ Ğ´Ğ»Ñ Ğ¼ÑƒÑĞ¾Ñ€Ğ°
        self.detector = EnsembleDetector(
            yolo_model_path=yolo_path,
            detr_model_path=detr_path,
            detr_processor_path=detr_processor_path,
            conf_threshold=conf_threshold
        )
        self.garbage_classes = ['glass', 'plastic', 'metal', 'paper', 'organic']
        print("âœ… ĞĞ½ÑĞ°Ğ¼Ğ±Ğ»ÑŒ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ² Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½!")
        
        # Ğ’Ğ°Ñˆ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ ÑÑ†ĞµĞ½
        self.scene_classifier = None
        if scene_classifier_path and Path(scene_classifier_path).exists():
            self.scene_classifier = SceneClassifierInference(scene_classifier_path)
            print("âœ… ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ ÑÑ†ĞµĞ½ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½!")
        else:
            print("âš ï¸ ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ ÑÑ†ĞµĞ½ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½. ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ ÑÑ†ĞµĞ½Ñ‹ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾.")
            print("   ĞĞ±ÑƒÑ‡Ğ¸Ñ‚Ğµ ĞµĞ³Ğ¾: python train_scene_classifier.py")
    
    def detect_garbage(self, image):
        """Ğ”ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ Ğ¼ÑƒÑĞ¾Ñ€Ğ° Ğ²Ğ°ÑˆĞ¸Ğ¼ Ğ°Ğ½ÑĞ°Ğ¼Ğ±Ğ»ĞµĞ¼"""
        if isinstance(image, str):
            image = Image.open(image).convert('RGB')
        return self.detector.detect(image)
    
    def classify_scene(self, image):
        """ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ÑÑ†ĞµĞ½Ñ‹ Ğ²Ğ°ÑˆĞ¸Ğ¼ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ¾Ğ¼"""
        if self.scene_classifier is None:
            return {'class': 'unknown', 'confidence': 0.0}
        
        if isinstance(image, str):
            image = Image.open(image).convert('RGB')
        return self.scene_classifier.predict(image)
    
    def get_garbage_counts(self, detections):
        """ĞŸĞ¾Ğ´ÑÑ‡Ñ‘Ñ‚ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ğ¼ÑƒÑĞ¾Ñ€Ğ°"""
        counts = {cls: 0 for cls in self.garbage_classes}
        for det in detections:
            label = det['label']
            if label in counts:
                counts[label] += 1
        return counts
    
    def describe(self, image_path):
        """
        ĞŸĞ¾Ğ»Ğ½Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ: Ğ¼ÑƒÑĞ¾Ñ€ + ÑÑ†ĞµĞ½Ğ°
        ĞŸÑ€Ğ¸Ğ¼ĞµÑ€: "There is 2 plastic objects on the grass"
        """
        if isinstance(image_path, str):
            image = Image.open(image_path).convert('RGB')
        else:
            image = image_path
        
        # Ğ”ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ Ğ¼ÑƒÑĞ¾Ñ€Ğ°
        detections = self.detector.detect(image)
        counts = self.get_garbage_counts(detections)
        total = sum(counts.values())
        
        # ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ÑÑ†ĞµĞ½Ñ‹
        scene = self.classify_scene(image)
        scene_name = scene['class']
        scene_conf = scene['confidence']
        
        # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ¼ÑƒÑĞ¾Ñ€Ğ°
        if total == 0:
            garbage_str = "No garbage"
        else:
            items = []
            for cls, count in counts.items():
                if count > 0:
                    items.append(f"{count} {cls}")
            garbage_str = "There is " + ", ".join(items)
        
        # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ
        if scene_name != 'unknown' and scene_conf > 0.5:
            # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ³ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ ÑÑ†ĞµĞ½Ñ‹
            preposition = self._get_preposition(scene_name)
            description = f"{garbage_str} {preposition} the {scene_name}."
        else:
            description = f"{garbage_str} detected."
        
        return description
    
    def _get_preposition(self, scene):
        """ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ³ Ğ´Ğ»Ñ ÑÑ†ĞµĞ½Ñ‹"""
        if scene in ['water']:
            return 'near'
        elif scene in ['indoor', 'floor']:
            return 'on'
        else:
            return 'on'
    
    def answer(self, image_path, question):
        """ĞÑ‚Ğ²ĞµÑ‚ Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¾ Ğ¼ÑƒÑĞ¾Ñ€Ğµ Ğ¸ ÑÑ†ĞµĞ½Ğµ"""
        if isinstance(image_path, str):
            image = Image.open(image_path).convert('RGB')
        else:
            image = image_path
        
        detections = self.detector.detect(image)
        counts = self.get_garbage_counts(detections)
        total = sum(counts.values())
        q = question.lower()
        
        # Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¾ ÑÑ†ĞµĞ½Ğµ
        if any(word in q for word in ['where', 'scene', 'surface', 'ground', 'location']):
            scene = self.classify_scene(image)
            if scene['class'] != 'unknown':
                return f"The scene is classified as: {scene['class']} ({scene['confidence']:.0%} confidence)."
            else:
                return "Scene classifier not available. Train it first!"
        
        # Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¾ Ğ¼ÑƒÑĞ¾Ñ€Ğµ
        if "what" in q or "describe" in q:
            return self.describe(image)
        
        if "how many" in q:
            for cls in self.garbage_classes:
                if cls in q:
                    c = counts[cls]
                    return f"{c} {cls} object{'s' if c != 1 else ''} detected."
            return f"{total} garbage object{'s' if total != 1 else ''} detected in total."
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ñ
        for cls in self.garbage_classes:
            if cls in q:
                c = counts[cls]
                if c > 0:
                    return f"Yes, {c} {cls} object{'s' if c != 1 else ''} detected."
                else:
                    return f"No {cls} detected."
        
        # Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¾ Ñ‚Ğ¸Ğ¿Ğ°Ñ… ÑÑ†ĞµĞ½
        for scene_cls in SCENE_CLASSES:
            if scene_cls in q:
                scene = self.classify_scene(image)
                if scene['class'] == scene_cls:
                    return f"Yes, the scene appears to be {scene_cls} ({scene['confidence']:.0%})."
                else:
                    return f"No, the scene is classified as {scene['class']}, not {scene_cls}."
        
        # ĞŸĞ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ
        return self.describe(image)
    
    def get_full_analysis(self, image_path):
        """ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ"""
        if isinstance(image_path, str):
            image = Image.open(image_path).convert('RGB')
        else:
            image = image_path
        
        detections = self.detector.detect(image)
        scene = self.classify_scene(image)
        counts = self.get_garbage_counts(detections)
        
        return {
            'garbage': {
                'detections': detections,
                'counts': counts,
                'total': sum(counts.values())
            },
            'scene': scene,
            'description': self.describe(image)
        }


# === Ğ”Ğ»Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° ===
if __name__ == "__main__":
    import random
    
    print("\n" + "="*60)
    print("ĞŸĞĞ›ĞĞĞ¯ VLM ĞĞ Ğ¥Ğ˜Ğ¢Ğ•ĞšĞ¢Ğ£Ğ Ğ")
    print("CV = Ğ’Ğ°Ñˆ Ğ°Ğ½ÑĞ°Ğ¼Ğ±Ğ»ÑŒ + Ğ’Ğ°Ñˆ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ ÑÑ†ĞµĞ½")
    print("="*60)
    
    vlm = CompleteVLM(
        yolo_path="models/yolo/yolov8x/best.pt",
        detr_path="models/rt-detr/rt-detr-101/m",
        detr_processor_path="models/rt-detr/rt-detr-101/p",
        scene_classifier_path="models/scene_classifier.pt",
        conf_threshold=0.5
    )
    
    # Ğ¢ĞµÑÑ‚
    valid_dir = Path("data/roboflow_dataset/valid")
    test_dir = Path("data/roboflow_dataset/test")
    images = list(valid_dir.glob("*.jpg")) + list(test_dir.glob("*.jpg"))
    
    if images:
        img = random.choice(images)
        print(f"\nğŸ“· Ğ¢ĞµÑÑ‚: {img.name}")
        
        analysis = vlm.get_full_analysis(str(img))
        
        print(f"\nğŸ¯ ĞœÑƒÑĞ¾Ñ€: {analysis['garbage']['total']} Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ²")
        for cls, count in analysis['garbage']['counts'].items():
            if count > 0:
                print(f"   - {cls}: {count}")
        
        print(f"\nğŸŒ Ğ¡Ñ†ĞµĞ½Ğ°: {analysis['scene']['class']} ({analysis['scene']['confidence']:.0%})")
        print(f"\nğŸ“ ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ: {analysis['description']}")
        
        print("\nğŸ’¬ Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹:")
        for q in ["Is there plastic?", "How many objects?", "Where is it?"]:
            print(f"   Q: {q}")
            print(f"   A: {vlm.answer(str(img), q)}")

