"""
ĞŸĞĞ›ĞĞĞ¯ VLM Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°
- Ğ’Ğ°Ñˆ Ğ°Ğ½ÑĞ°Ğ¼Ğ±Ğ»ÑŒ (YOLO + RT-DETR) Ğ´Ğ»Ñ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸ Ğ¼ÑƒÑĞ¾Ñ€Ğ°
- Ğ’Ğ°Ñˆ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ ÑÑ†ĞµĞ½ Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ (YOLO Ğ¸Ğ»Ğ¸ MobileNet)

Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: "There is plastic on the grass"
"""

import sys
sys.path.append('.')
from PIL import Image
from pathlib import Path
import torch

from vlm_annotation.ensemble_detector import EnsembleDetector

# ĞšĞ»Ğ°ÑÑÑ‹ ÑÑ†ĞµĞ½
SCENE_CLASSES = ['grass', 'marshy', 'rocky', 'sandy']


def load_scene_classifier(model_path: str):
    """
    Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ° ÑÑ†ĞµĞ½ (Ğ°Ğ²Ñ‚Ğ¾Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¸Ğ¿Ğ°: YOLO Ğ¸Ğ»Ğ¸ MobileNet)
    """
    if model_path is None or not Path(model_path).exists():
        return None
    
    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ‚Ğ¸Ğ¿ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ğ¾ Ğ¿ÑƒÑ‚Ğ¸
    if 'yolo' in model_path.lower():
        from train_scene_yolo import SceneClassifierYOLO
        return SceneClassifierYOLO(model_path)
    else:
        from train_scene_classifier import SceneClassifierInference
        return SceneClassifierInference(model_path)


class CompleteVLM:
    """
    VLM Ğ³Ğ´Ğµ Ğ’Ğ¡Ğ¯ CV Ñ‡Ğ°ÑÑ‚ÑŒ - ÑÑ‚Ğ¾ Ğ²Ğ°ÑˆĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸:
    1. ĞĞ½ÑĞ°Ğ¼Ğ±Ğ»ÑŒ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ² Ğ¼ÑƒÑĞ¾Ñ€Ğ°
    2. ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ ÑÑ†ĞµĞ½
    """
    
    def __init__(
        self,
        yolo_path: str,
        detr_path: str,
        detr_processor_path: str,
        scene_classifier_path: str = None,
        conf_threshold: float = 0.5
    ):
        # Ğ’Ğ°Ñˆ Ğ°Ğ½ÑĞ°Ğ¼Ğ±Ğ»ÑŒ Ğ´Ğ»Ñ Ğ¼ÑƒÑĞ¾Ñ€Ğ°
        self.detector = EnsembleDetector(
            yolo_model_path=yolo_path,
            detr_model_path=detr_path,
            detr_processor_path=detr_processor_path,
            conf_threshold=conf_threshold
        )
        self.garbage_classes = ['glass', 'plastic', 'metal', 'paper', 'organic']
        print("âœ… ĞĞ½ÑĞ°Ğ¼Ğ±Ğ»ÑŒ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ² Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½!")
        
        # Ğ’Ğ°Ñˆ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ ÑÑ†ĞµĞ½ (YOLO Ğ¸Ğ»Ğ¸ MobileNet)
        self.scene_classifier = None
        if scene_classifier_path and Path(scene_classifier_path).exists():
            self.scene_classifier = load_scene_classifier(scene_classifier_path)
            classifier_type = "YOLO" if 'yolo' in scene_classifier_path.lower() else "MobileNet"
            print(f"âœ… ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ ÑÑ†ĞµĞ½ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ ({classifier_type})!")
        else:
            print("âš ï¸ ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ ÑÑ†ĞµĞ½ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½. ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ ÑÑ†ĞµĞ½Ñ‹ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾.")
            print("   ĞĞ±ÑƒÑ‡Ğ¸Ñ‚Ğµ ĞµĞ³Ğ¾: python train_scene_yolo.py")
    
    def detect_garbage(self, image):
        """Ğ”ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ Ğ¼ÑƒÑĞ¾Ñ€Ğ° Ğ²Ğ°ÑˆĞ¸Ğ¼ Ğ°Ğ½ÑĞ°Ğ¼Ğ±Ğ»ĞµĞ¼"""
        if isinstance(image, str):
            image = Image.open(image).convert('RGB')
        return self.detector.detect(image)
    
    def classify_scene(self, image):
        """ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ÑÑ†ĞµĞ½Ñ‹ Ğ²Ğ°ÑˆĞ¸Ğ¼ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ¾Ğ¼"""
        if self.scene_classifier is None:
            return {'class': 'unknown', 'confidence': 0.0}
        
        if isinstance(image, str):
            image = Image.open(image).convert('RGB')
        return self.scene_classifier.predict(image)
    
    def get_garbage_counts(self, detections):
        """ĞŸĞ¾Ğ´ÑÑ‡Ñ‘Ñ‚ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ğ¼ÑƒÑĞ¾Ñ€Ğ°"""
        counts = {cls: 0 for cls in self.garbage_classes}
        for det in detections:
            label = det['label']
            if label in counts:
                counts[label] += 1
        return counts
    
    def describe(self, image_path):
        """
        ĞŸĞ¾Ğ»Ğ½Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ: Ğ¼ÑƒÑĞ¾Ñ€ + ÑÑ†ĞµĞ½Ğ°
        ĞŸÑ€Ğ¸Ğ¼ĞµÑ€: "There is 2 plastic objects on the grass"
        """
        if isinstance(image_path, str):
            image = Image.open(image_path).convert('RGB')
        else:
            image = image_path
        
        # Ğ”ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ Ğ¼ÑƒÑĞ¾Ñ€Ğ°
        detections = self.detector.detect(image)
        counts = self.get_garbage_counts(detections)
        total = sum(counts.values())
        
        # ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ÑÑ†ĞµĞ½Ñ‹
        scene = self.classify_scene(image)
        scene_name = scene['class']
        scene_conf = scene['confidence']
        
        # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ¼ÑƒÑĞ¾Ñ€Ğ°
        if total == 0:
            garbage_str = "No garbage"
        else:
            items = []
            for cls, count in counts.items():
                if count > 0:
                    items.append(f"{count} {cls}")
            garbage_str = "There is " + ", ".join(items)
        
        # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ
        # ĞŸĞ¾Ñ€Ğ¾Ğ³ 0.8 - ĞµÑĞ»Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ°, Ğ½Ğµ ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°ĞµĞ¼ ÑÑ†ĞµĞ½Ñƒ
        if scene_name != 'unknown' and scene_conf >= 0.8:
            preposition = self._get_preposition(scene_name)
            description = f"{garbage_str} {preposition} the {scene_name}."
        else:
            description = f"{garbage_str} detected."
        
        return description
    
    def _get_preposition(self, scene):
        """ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ³ Ğ´Ğ»Ñ ÑÑ†ĞµĞ½Ñ‹"""
        if scene in ['marshy']:
            return 'in'
        elif scene in ['rocky']:
            return 'on'
        elif scene in ['sandy']:
            return 'on'
        else:  # grass Ğ¸ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ
            return 'on'
    
    def answer(self, image_path, question):
        """ĞÑ‚Ğ²ĞµÑ‚ Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¾ Ğ¼ÑƒÑĞ¾Ñ€Ğµ Ğ¸ ÑÑ†ĞµĞ½Ğµ"""
        if isinstance(image_path, str):
            image = Image.open(image_path).convert('RGB')
        else:
            image = image_path
        
        detections = self.detector.detect(image)
        counts = self.get_garbage_counts(detections)
        total = sum(counts.values())
        q = question.lower()
        
        # Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¾ ÑÑ†ĞµĞ½Ğµ
        if any(word in q for word in ['where', 'scene', 'surface', 'ground', 'location']):
            scene = self.classify_scene(image)
            if scene['class'] != 'unknown' and scene['confidence'] >= 0.8:
                return f"The scene is: {scene['class']} ({scene['confidence']:.0%} confidence)."
            elif scene['class'] != 'unknown':
                return "Scene classification uncertain (confidence below 80%)."
            else:
                return "Scene classifier not available. Train it first!"
        
        # Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¾ Ğ¼ÑƒÑĞ¾Ñ€Ğµ
        if "what" in q or "describe" in q:
            return self.describe(image)
        
        if "how many" in q:
            for cls in self.garbage_classes:
                if cls in q:
                    c = counts[cls]
                    return f"{c} {cls} object{'s' if c != 1 else ''} detected."
            return f"{total} garbage object{'s' if total != 1 else ''} detected in total."
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ñ
        for cls in self.garbage_classes:
            if cls in q:
                c = counts[cls]
                if c > 0:
                    return f"Yes, {c} {cls} object{'s' if c != 1 else ''} detected."
                else:
                    return f"No {cls} detected."
        
        # Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¾ Ñ‚Ğ¸Ğ¿Ğ°Ñ… ÑÑ†ĞµĞ½
        for scene_cls in SCENE_CLASSES:
            if scene_cls in q:
                scene = self.classify_scene(image)
                if scene['class'] == scene_cls and scene['confidence'] >= 0.8:
                    return f"Yes, the scene appears to be {scene_cls} ({scene['confidence']:.0%})."
                elif scene['confidence'] >= 0.8:
                    return f"No, the scene is classified as {scene['class']}, not {scene_cls}."
                else:
                    return "Scene classification uncertain (confidence below 80%)."
        
        # ĞŸĞ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ
        return self.describe(image)
    
    def get_full_analysis(self, image_path):
        """ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ"""
        if isinstance(image_path, str):
            image = Image.open(image_path).convert('RGB')
        else:
            image = image_path
        
        detections = self.detector.detect(image)
        scene = self.classify_scene(image)
        counts = self.get_garbage_counts(detections)
        
        return {
            'garbage': {
                'detections': detections,
                'counts': counts,
                'total': sum(counts.values())
            },
            'scene': scene,
            'description': self.describe(image)
        }


# === Ğ”Ğ»Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° ===
if __name__ == "__main__":
    import random
    
    print("\n" + "="*60)
    print("ĞŸĞĞ›ĞĞĞ¯ VLM ĞĞ Ğ¥Ğ˜Ğ¢Ğ•ĞšĞ¢Ğ£Ğ Ğ")
    print("CV = Ğ’Ğ°Ñˆ Ğ°Ğ½ÑĞ°Ğ¼Ğ±Ğ»ÑŒ + Ğ’Ğ°Ñˆ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ ÑÑ†ĞµĞ½ (YOLO)")
    print("="*60)
    
    # ĞŸÑ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚: YOLO ÑÑ†ĞµĞ½Ğ° > MobileNet ÑÑ†ĞµĞ½Ğ°
    scene_path = None
    if Path("models/scene_classifier_yolo.pt").exists():
        scene_path = "models/scene_classifier_yolo.pt"
    elif Path("models/scene_classifier.pt").exists():
        scene_path = "models/scene_classifier.pt"
    
    vlm = CompleteVLM(
        yolo_path="models/yolo/yolov8x/best.pt",
        detr_path="models/rt-detr/rt-detr-101/m",
        detr_processor_path="models/rt-detr/rt-detr-101/p",
        scene_classifier_path=scene_path,
        conf_threshold=0.5
    )
    
    # Ğ¢ĞµÑÑ‚
    valid_dir = Path("data/roboflow_dataset/valid")
    test_dir = Path("data/roboflow_dataset/test")
    images = list(valid_dir.glob("*.jpg")) + list(test_dir.glob("*.jpg"))
    
    if images:
        img = random.choice(images)
        print(f"\nğŸ“· Ğ¢ĞµÑÑ‚: {img.name}")
        
        analysis = vlm.get_full_analysis(str(img))
        
        print(f"\nğŸ¯ ĞœÑƒÑĞ¾Ñ€: {analysis['garbage']['total']} Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ²")
        for cls, count in analysis['garbage']['counts'].items():
            if count > 0:
                print(f"   - {cls}: {count}")
        
        print(f"\nğŸŒ Ğ¡Ñ†ĞµĞ½Ğ°: {analysis['scene']['class']} ({analysis['scene']['confidence']:.0%})")
        print(f"\nğŸ“ ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ: {analysis['description']}")
        
        print("\nğŸ’¬ Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹:")
        for q in ["Is there plastic?", "How many objects?", "Where is it?"]:
            print(f"   Q: {q}")
            print(f"   A: {vlm.answer(str(img), q)}")

