{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ—‘ï¸ ÐŸÐžÐ›ÐÐÐ¯ VLM Ð´Ð»Ñ Ð¼ÑƒÑÐ¾Ñ€Ð°\n",
        "\n",
        "**CV Ñ‡Ð°ÑÑ‚ÑŒ = Ð²Ð°ÑˆÐ¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸:**\n",
        "1. ÐÐ½ÑÐ°Ð¼Ð±Ð»ÑŒ Ð´ÐµÑ‚ÐµÐºÑ‚Ð¾Ñ€Ð¾Ð² (YOLO + RT-DETR) â†’ Ð¼ÑƒÑÐ¾Ñ€\n",
        "2. ÐšÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€ ÑÑ†ÐµÐ½ (MobileNet) â†’ grass, marshy, rocky, sandy\n",
        "\n",
        "**Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚:** \"There is 2 plastic on the grass\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Ð£ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ°\n",
        "!pip install -q roboflow ultralytics supervision transformers pillow tqdm\n",
        "!git lfs install\n",
        "!git clone https://github.com/sry4theweight/VLM_garbage.git\n",
        "%cd VLM_garbage\n",
        "\n",
        "import torch\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ð¼ÑƒÑÐ¾Ñ€Ð°\n",
        "!python download_roboflow_dataset.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ ÑÑ†ÐµÐ½ (Roboflow Terrain Classification)\n",
        "!python download_scene_dataset.py --download\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ð° ÑÑ†ÐµÐ½ (~5-10 Ð¼Ð¸Ð½ Ð½Ð° GPU)\n",
        "!python train_scene_classifier.py --train_dir data/scene_dataset/train --val_dir data/scene_dataset/val --output models/scene_classifier.pt --epochs 15 --batch_size 32\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¿Ð¾Ð»Ð½Ð¾Ð¹ VLM\n",
        "from VLM_Complete import CompleteVLM\n",
        "from pathlib import Path\n",
        "import random, matplotlib.pyplot as plt, matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "\n",
        "vlm = CompleteVLM(\n",
        "    yolo_path=\"models/yolo/yolov8x/best.pt\",\n",
        "    detr_path=\"models/rt-detr/rt-detr-101/m\",\n",
        "    detr_processor_path=\"models/rt-detr/rt-detr-101/p\",\n",
        "    scene_classifier_path=\"models/scene_classifier.pt\",\n",
        "    conf_threshold=0.5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ\n",
        "valid = Path(\"data/roboflow_dataset/valid\")\n",
        "test = Path(\"data/roboflow_dataset/test\")\n",
        "images = list(valid.glob(\"*.jpg\")) + list(test.glob(\"*.jpg\"))\n",
        "print(f\"âœ… {len(images)} Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹\")\n",
        "\n",
        "COLORS = {'glass':'green', 'plastic':'red', 'metal':'cyan', 'paper':'yellow', 'organic':'lime'}\n",
        "\n",
        "def test_image(img_path):\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    analysis = vlm.get_full_analysis(img)\n",
        "    fig, ax = plt.subplots(figsize=(10,7))\n",
        "    ax.imshow(img)\n",
        "    for d in analysis['garbage']['detections']:\n",
        "        b = d['box']\n",
        "        c = COLORS.get(d['label'], 'white')\n",
        "        ax.add_patch(patches.Rectangle((b[0],b[1]), b[2]-b[0], b[3]-b[1], lw=2, ec=c, fc='none'))\n",
        "        ax.text(b[0], b[1]-5, f\"{d['label']} {d['confidence']:.0%}\", color=c, fontsize=9, weight='bold')\n",
        "    scene = analysis['scene']\n",
        "    title = f\"Scene: {scene['class']} ({scene['confidence']:.0%})\" if scene['confidence'] >= 0.8 else \"Scene: uncertain\"\n",
        "    ax.set_title(f\"{title} | Objects: {analysis['garbage']['total']}\")\n",
        "    ax.axis('off')\n",
        "    plt.show()\n",
        "    print(f\"ðŸ“ {analysis['description']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Ð¢ÐµÑÑ‚ Ð½Ð° 3 Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑÑ…\n",
        "for img in random.sample(images, min(3, len(images))):\n",
        "    print(f\"\\n{'='*60}\\nðŸ“· {img.name}\")\n",
        "    test_image(img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. Ð˜Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹\n",
        "img = random.choice(images)\n",
        "test_image(img)\n",
        "for q in [\"What is here?\", \"Is there plastic?\", \"How many objects?\", \"Where is the garbage?\"]:\n",
        "    print(f\"â“ {q}\\nâœ… {vlm.answer(str(img), q)}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9. Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð½Ð° Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir -p /content/drive/MyDrive/VLM_garbage/models\n",
        "!cp models/scene_classifier.pt /content/drive/MyDrive/VLM_garbage/models/\n",
        "!cp -r models/yolo models/rt-detr /content/drive/MyDrive/VLM_garbage/models/ 2>/dev/null || true\n",
        "!cp VLM_Complete.py train_scene_classifier.py /content/drive/MyDrive/VLM_garbage/\n",
        "print(\"âœ… Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
