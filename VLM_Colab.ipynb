{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üóëÔ∏è –ü–û–õ–ù–ê–Ø VLM –¥–ª—è –º—É—Å–æ—Ä–∞\n",
        "\n",
        "**–í–∞—à –≤–∫–ª–∞–¥ = –í–°–Ø CV —á–∞—Å—Ç—å:**\n",
        "1. –ê–Ω—Å–∞–º–±–ª—å –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–≤ (YOLO + RT-DETR) ‚Üí –º—É—Å–æ—Ä\n",
        "2. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å—Ü–µ–Ω (MobileNet) ‚Üí terrain\n",
        "\n",
        "**–†–µ–∑—É–ª—å—Ç–∞—Ç:** \"There is 2 plastic on the grass\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞\n",
        "!pip install -q roboflow ultralytics supervision transformers pillow tqdm\n",
        "!git lfs install\n",
        "!git clone https://github.com/sry4theweight/VLM_garbage.git\n",
        "%cd VLM_garbage\n",
        "\n",
        "import torch\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. –°–∫–∞—á–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –º—É—Å–æ—Ä–∞\n",
        "!python download_roboflow_dataset.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. –°–∫–∞—á–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç —Å—Ü–µ–Ω (Roboflow Terrain Classification)\n",
        "!python download_scene_dataset.py --download\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. –û–±—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Å—Ü–µ–Ω (~5-10 –º–∏–Ω –Ω–∞ GPU)\n",
        "!python train_scene_classifier.py --train_dir data/scene_dataset/train --val_dir data/scene_dataset/val --output models/scene_classifier.pt --epochs 15 --batch_size 32\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ–ª–Ω–æ–π VLM\n",
        "from VLM_Complete import CompleteVLM\n",
        "from pathlib import Path\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "\n",
        "vlm = CompleteVLM(\n",
        "    yolo_path=\"models/yolo/yolov8x/best.pt\",\n",
        "    detr_path=\"models/rt-detr/rt-detr-101/m\",\n",
        "    detr_processor_path=\"models/rt-detr/rt-detr-101/p\",\n",
        "    scene_classifier_path=\"models/scene_classifier.pt\",\n",
        "    conf_threshold=0.5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. –°–æ–±–∏—Ä–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ë–ï–ó –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π\n",
        "valid = Path(\"data/roboflow_dataset/valid\")\n",
        "test = Path(\"data/roboflow_dataset/test\")\n",
        "images = list(valid.glob(\"*.jpg\")) + list(test.glob(\"*.jpg\"))\n",
        "print(f\"‚úÖ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π\")\n",
        "\n",
        "COLORS = {'glass':'green', 'plastic':'red', 'metal':'cyan', 'paper':'yellow', 'organic':'lime'}\n",
        "\n",
        "def test_image(img_path):\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    analysis = vlm.get_full_analysis(img)\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(10,7))\n",
        "    ax.imshow(img)\n",
        "    for d in analysis['garbage']['detections']:\n",
        "        b = d['box']\n",
        "        c = COLORS.get(d['label'], 'white')\n",
        "        ax.add_patch(patches.Rectangle((b[0],b[1]), b[2]-b[0], b[3]-b[1], lw=2, ec=c, fc='none'))\n",
        "        ax.text(b[0], b[1]-5, f\"{d['label']} {d['confidence']:.0%}\", color=c, fontsize=9, weight='bold')\n",
        "    \n",
        "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ü–µ–Ω—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å >= 80%\n",
        "    scene_info = analysis['scene']\n",
        "    if scene_info['confidence'] >= 0.8:\n",
        "        title = f\"Scene: {scene_info['class']} ({scene_info['confidence']:.0%}) | Objects: {analysis['garbage']['total']}\"\n",
        "    else:\n",
        "        title = f\"Scene: uncertain | Objects: {analysis['garbage']['total']}\"\n",
        "    ax.set_title(title)\n",
        "    ax.axis('off')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nüìù {analysis['description']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. –¢–µ—Å—Ç –Ω–∞ 3 —Å–ª—É—á–∞–π–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö\n",
        "for img in random.sample(images, min(3, len(images))):\n",
        "    print(f\"\\n{'='*60}\\nüì∑ {img.name}\")\n",
        "    test_image(img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ç–µ—Å—Ç —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏\n",
        "img = random.choice(images)\n",
        "test_image(img)\n",
        "\n",
        "questions = [\"What is in this image?\", \"Is there any plastic?\", \"How many objects?\", \"Where is the garbage?\"]\n",
        "print(\"\\nüí¨ –í–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã:\")\n",
        "for q in questions:\n",
        "    print(f\"\\n‚ùì {q}\")\n",
        "    print(f\"‚úÖ {vlm.answer(str(img), q)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞ Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir -p /content/drive/MyDrive/VLM_garbage/models\n",
        "!cp models/scene_classifier.pt /content/drive/MyDrive/VLM_garbage/models/\n",
        "!cp -r models/yolo models/rt-detr /content/drive/MyDrive/VLM_garbage/models/\n",
        "!cp VLM_Complete.py train_scene_classifier.py /content/drive/MyDrive/VLM_garbage/\n",
        "print(\"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –Ω–∞ Google Drive!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üóëÔ∏è –ü–û–õ–ù–ê–Ø VLM –¥–ª—è –º—É—Å–æ—Ä–∞\n",
        "\n",
        "**–í–∞—à –≤–∫–ª–∞–¥ = –í–°–Ø CV —á–∞—Å—Ç—å:**\n",
        "1. –ê–Ω—Å–∞–º–±–ª—å –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–≤ (YOLO + RT-DETR) ‚Üí –º—É—Å–æ—Ä\n",
        "2. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å—Ü–µ–Ω (MobileNet) ‚Üí grass, road, sand...\n",
        "\n",
        "**–†–µ–∑—É–ª—å—Ç–∞—Ç:** \"There is 2 plastic on the grass\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞\n",
        "!pip install -q kagglehub ultralytics supervision transformers pillow roboflow tqdm\n",
        "!git lfs install\n",
        "!git clone https://github.com/sry4theweight/VLM_garbage.git\n",
        "%cd VLM_garbage\n",
        "\n",
        "import torch\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. –°–∫–∞—á–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –º—É—Å–æ—Ä–∞\n",
        "!python download_roboflow_dataset.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. –°–∫–∞—á–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç —Å—Ü–µ–Ω (Intel Image Classification)\n",
        "!python download_scene_dataset.py --download\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. –û–±—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Å—Ü–µ–Ω (~5-10 –º–∏–Ω—É—Ç –Ω–∞ GPU)\n",
        "!python train_scene_classifier.py --train_dir data/scene_dataset/train --val_dir data/scene_dataset/val --output models/scene_classifier.pt --epochs 10 --batch_size 32\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ–ª–Ω–æ–π VLM\n",
        "from VLM_Complete import CompleteVLM\n",
        "from pathlib import Path\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "\n",
        "vlm = CompleteVLM(\n",
        "    yolo_path=\"models/yolo/yolov8x/best.pt\",\n",
        "    detr_path=\"models/rt-detr/rt-detr-101/m\",\n",
        "    detr_processor_path=\"models/rt-detr/rt-detr-101/p\",\n",
        "    scene_classifier_path=\"models/scene_classifier.pt\",\n",
        "    conf_threshold=0.5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö –ë–ï–ó –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π\n",
        "valid = Path(\"data/roboflow_dataset/valid\")\n",
        "test = Path(\"data/roboflow_dataset/test\")\n",
        "images = list(valid.glob(\"*.jpg\")) + list(test.glob(\"*.jpg\"))\n",
        "print(f\"‚úÖ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π\")\n",
        "\n",
        "COLORS = {'glass':'green', 'plastic':'red', 'metal':'cyan', 'paper':'yellow', 'organic':'lime'}\n",
        "\n",
        "def test_image(img_path):\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    analysis = vlm.get_full_analysis(img)\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(10,7))\n",
        "    ax.imshow(img)\n",
        "    for d in analysis['garbage']['detections']:\n",
        "        b = d['box']\n",
        "        c = COLORS.get(d['label'], 'white')\n",
        "        ax.add_patch(patches.Rectangle((b[0],b[1]), b[2]-b[0], b[3]-b[1], lw=2, ec=c, fc='none'))\n",
        "        ax.text(b[0], b[1]-5, f\"{d['label']} {d['confidence']:.0%}\", color=c, fontsize=9, weight='bold')\n",
        "    ax.set_title(f\"Scene: {analysis['scene']['class']} | Objects: {analysis['garbage']['total']}\")\n",
        "    ax.axis('off')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nüìù {analysis['description']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. –¢–µ—Å—Ç –Ω–∞ 3 —Å–ª—É—á–∞–π–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö\n",
        "for img in random.sample(images, min(3, len(images))):\n",
        "    print(f\"\\n{'='*60}\\nüì∑ {img.name}\")\n",
        "    test_image(img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã\n",
        "img = random.choice(images)\n",
        "test_image(img)\n",
        "\n",
        "questions = [\n",
        "    \"What is in this image?\",\n",
        "    \"Is there any plastic?\",\n",
        "    \"How many objects?\",\n",
        "    \"Where is the garbage?\",  # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å—Ü–µ–Ω!\n",
        "]\n",
        "\n",
        "print(\"\\nüí¨ –í–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã:\")\n",
        "for q in questions:\n",
        "    print(f\"\\n‚ùì {q}\")\n",
        "    print(f\"‚úÖ {vlm.answer(str(img), q)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞ Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir -p /content/drive/MyDrive/VLM_garbage/models\n",
        "!cp models/scene_classifier.pt /content/drive/MyDrive/VLM_garbage/models/\n",
        "!cp -r models/yolo models/rt-detr /content/drive/MyDrive/VLM_garbage/models/\n",
        "!cp VLM_Complete.py VLM_Honest.py /content/drive/MyDrive/VLM_garbage/\n",
        "print(\"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –Ω–∞ Google Drive!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
