"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–≤ (YOLO + RT-DETR) –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ Roboflow

–ú–µ—Ç—Ä–∏–∫–∏:
- mAP@50 - mean Average Precision –ø—Ä–∏ IoU=0.5
- mAP@50:95 - mean Average Precision, —É—Å—Ä–µ–¥–Ω—ë–Ω–Ω–æ–µ –ø–æ IoU –æ—Ç 0.5 –¥–æ 0.95
- mAR@50 - mean Average Recall –ø—Ä–∏ IoU=0.5

–ó–∞–ø—É—Å–∫:
    python test_ensemble_detector.py
    python test_ensemble_detector.py --conf 0.5
    python test_ensemble_detector.py --split valid
"""

import json
import time
import argparse
import numpy as np
from pathlib import Path
from PIL import Image
from collections import defaultdict
from tqdm import tqdm


# –ö–ª–∞—Å—Å—ã –º—É—Å–æ—Ä–∞ (–±–µ–∑ garb-garbage)
GARBAGE_CLASSES = ['glass', 'metal', 'organic', 'paper', 'plastic']


def load_coco_annotations(annotation_file: str) -> dict:
    """–ó–∞–≥—Ä—É–∑–∫–∞ COCO –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π"""
    print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π: {annotation_file}")
    
    with open(annotation_file, 'r', encoding='utf-8') as f:
        coco = json.load(f)
    
    images = {img['id']: img for img in coco['images']}
    categories = {cat['id']: cat['name'] for cat in coco['categories']}
    
    print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {list(categories.values())}")
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
    annotations_by_image = defaultdict(list)
    skipped = 0
    
    for ann in coco['annotations']:
        image_id = ann['image_id']
        category_id = ann['category_id']
        bbox = ann['bbox']  # [x, y, width, height] –≤ COCO —Ñ–æ—Ä–º–∞—Ç–µ
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ [x1, y1, x2, y2]
        x1, y1, w, h = bbox
        x2, y2 = x1 + w, y1 + h
        
        category_name = categories.get(category_id, 'unknown')
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º garb-garbage
        if category_name == 'garb-garbage' or category_name not in GARBAGE_CLASSES:
            skipped += 1
            continue
            
        annotations_by_image[image_id].append({
            'bbox': [x1, y1, x2, y2],
            'label': category_name
        })
    
    total_objects = sum(len(anns) for anns in annotations_by_image.values())
    print(f"   –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(images)}")
    print(f"   –û–±—ä–µ–∫—Ç–æ–≤: {total_objects} (–ø—Ä–æ–ø—É—â–µ–Ω–æ garb-garbage: {skipped})")
    
    return {
        'images': images,
        'categories': categories,
        'annotations': annotations_by_image
    }


def calculate_iou(box1: list, box2: list) -> float:
    """IoU –º–µ–∂–¥—É –¥–≤—É–º—è bbox [x1, y1, x2, y2]"""
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])
    
    intersection = max(0, x2 - x1) * max(0, y2 - y1)
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    union = area1 + area2 - intersection
    
    return intersection / union if union > 0 else 0


def compute_ap(recalls, precisions):
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ AP —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—é (COCO style)"""
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞—á–∞–ª—å–Ω—É—é –∏ –∫–æ–Ω–µ—á–Ω—É—é —Ç–æ—á–∫–∏
    recalls = np.concatenate([[0], recalls, [1]])
    precisions = np.concatenate([[0], precisions, [0]])
    
    # –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è precision (—É–±—ã–≤–∞—é—â–∞—è –æ–≥–∏–±–∞—é—â–∞—è)
    for i in range(len(precisions) - 2, -1, -1):
        precisions[i] = max(precisions[i], precisions[i + 1])
    
    # –ù–∞—Ö–æ–¥–∏–º —Ç–æ—á–∫–∏ –≥–¥–µ recall –º–µ–Ω—è–µ—Ç—Å—è
    indices = np.where(recalls[1:] != recalls[:-1])[0] + 1
    
    # –í—ã—á–∏—Å–ª—è–µ–º AP –∫–∞–∫ –ø–ª–æ—â–∞–¥—å –ø–æ–¥ –∫—Ä–∏–≤–æ–π
    ap = np.sum((recalls[indices] - recalls[indices - 1]) * precisions[indices])
    
    return ap


def evaluate_at_iou(all_predictions: dict, all_gt: dict, iou_threshold: float):
    """
    –û—Ü–µ–Ω–∫–∞ –ø—Ä–∏ –∑–∞–¥–∞–Ω–Ω–æ–º IoU threshold
    
    Returns:
        dict —Å AP –∏ AR –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
    """
    results = {}
    
    for cls in GARBAGE_CLASSES:
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ GT –¥–ª—è –∫–ª–∞—Å—Å–∞
        all_preds = []
        all_gts = []
        
        for img_id in all_predictions.keys():
            preds = [p for p in all_predictions[img_id] if p['label'] == cls]
            gts = [g for g in all_gt.get(img_id, []) if g['label'] == cls]
            
            for p in preds:
                all_preds.append({
                    'confidence': p['confidence'],
                    'box': p['box'],
                    'img_id': img_id
                })
            
            for g in gts:
                all_gts.append({
                    'bbox': g['bbox'],
                    'img_id': img_id,
                    'matched': False
                })
        
        if len(all_gts) == 0:
            results[cls] = {'ap': 0.0, 'recall': 0.0, 'precision': 0.0}
            continue
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ confidence
        all_preds = sorted(all_preds, key=lambda x: -x['confidence'])
        
        # –°—á–∏—Ç–∞–µ–º TP/FP –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        tp = np.zeros(len(all_preds))
        fp = np.zeros(len(all_preds))
        
        # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º matched GT –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
        gt_matched = {img_id: set() for img_id in all_predictions.keys()}
        
        for pred_idx, pred in enumerate(all_preds):
            img_id = pred['img_id']
            
            # –ù–∞—Ö–æ–¥–∏–º GT –¥–ª—è —ç—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            img_gts = [(i, g) for i, g in enumerate(all_gts) 
                      if g['img_id'] == img_id and i not in gt_matched[img_id]]
            
            best_iou = 0
            best_gt_idx = -1
            
            for gt_idx, gt in img_gts:
                iou = calculate_iou(pred['box'], gt['bbox'])
                if iou > best_iou:
                    best_iou = iou
                    best_gt_idx = gt_idx
            
            if best_iou >= iou_threshold and best_gt_idx >= 0:
                tp[pred_idx] = 1
                gt_matched[img_id].add(best_gt_idx)
            else:
                fp[pred_idx] = 1
        
        # –ö—É–º—É–ª—è—Ç–∏–≤–Ω—ã–µ —Å—É–º–º—ã
        tp_cumsum = np.cumsum(tp)
        fp_cumsum = np.cumsum(fp)
        
        # Precision –∏ Recall
        recalls = tp_cumsum / len(all_gts)
        precisions = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-10)
        
        # AP
        ap = compute_ap(recalls, precisions)
        
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π recall (–¥–ª—è AR)
        max_recall = recalls[-1] if len(recalls) > 0 else 0
        
        # Precision –ø—Ä–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–º recall
        final_precision = precisions[-1] if len(precisions) > 0 else 0
        
        results[cls] = {
            'ap': ap,
            'recall': max_recall,
            'precision': final_precision,
            'tp': int(tp_cumsum[-1]) if len(tp_cumsum) > 0 else 0,
            'fp': int(fp_cumsum[-1]) if len(fp_cumsum) > 0 else 0,
            'fn': len(all_gts) - (int(tp_cumsum[-1]) if len(tp_cumsum) > 0 else 0),
            'total_gt': len(all_gts),
            'total_pred': len(all_preds)
        }
    
    return results


def test_ensemble(
    dataset_dir: str = "data/complete_dataset",
    split: str = "test",
    yolo_path: str = "models/yolo/yolov8x/best.pt",
    detr_path: str = "models/rt-detr/rt-detr-101/m",
    detr_processor_path: str = "models/rt-detr/rt-detr-101/p",
    conf_threshold: float = 0.01,  # –ù–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ä–∞—Å—á—ë—Ç–∞ AP
    save_results: bool = True
):
    """
    –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ
    
    –ú–µ—Ç—Ä–∏–∫–∏:
    - mAP@50: mean Average Precision –ø—Ä–∏ IoU=0.5
    - mAP@50:95: mean AP, —É—Å—Ä–µ–¥–Ω—ë–Ω–Ω–æ–µ –ø–æ IoU –æ—Ç 0.5 –¥–æ 0.95 —Å —à–∞–≥–æ–º 0.05
    - mAR@50: mean Average Recall –ø—Ä–∏ IoU=0.5
    """
    print("\n" + "=" * 70)
    print("üî¨ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ê–ù–°–ê–ú–ë–õ–Ø –î–ï–¢–ï–ö–¢–û–†–û–í")
    print("=" * 70)
    
    # –ü—É—Ç–∏
    dataset_path = Path(dataset_dir)
    split_dir = dataset_path / split
    annotation_file = split_dir / "_annotations.coco.json"
    
    if not split_dir.exists():
        print(f"‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {split_dir}")
        return None
    
    if not annotation_file.exists():
        print(f"‚ùå –§–∞–π–ª –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω: {annotation_file}")
        return None
    
    print(f"\nüìÅ –î–∞—Ç–∞—Å–µ—Ç: {dataset_dir}")
    print(f"üìÅ Split: {split}")
    print(f"üìÅ Confidence threshold: {conf_threshold}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
    coco_data = load_coco_annotations(str(annotation_file))
    images = coco_data['images']
    annotations = coco_data['annotations']
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–Ω—Å–∞–º–±–ª—å
    print(f"\nüîß –ó–∞–≥—Ä—É–∑–∫–∞ –∞–Ω—Å–∞–º–±–ª—è...")
    print(f"   YOLO: {yolo_path}")
    print(f"   RT-DETR: {detr_path}")
    
    from vlm_annotation.ensemble_detector import EnsembleDetector
    
    detector = EnsembleDetector(
        yolo_model_path=yolo_path,
        detr_model_path=detr_path,
        detr_processor_path=detr_processor_path,
        conf_threshold=conf_threshold
    )
    print("‚úÖ –ê–Ω—Å–∞–º–±–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω!")
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    print(f"\nüöÄ –ó–∞–ø—É—Å–∫ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –Ω–∞ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö...")
    
    all_predictions = {}
    all_gt = {}
    inference_times = []
    processed = 0
    
    for img_id in tqdm(images.keys(), desc="–ò–Ω—Ñ–µ—Ä–µ–Ω—Å"):
        img_info = images[img_id]
        img_path = split_dir / img_info['file_name']
        
        if not img_path.exists():
            continue
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image = Image.open(img_path).convert('RGB')
        
        # –î–µ—Ç–µ–∫—Ü–∏—è
        start_time = time.time()
        predictions = detector.detect(image)
        inference_times.append(time.time() - start_time)
        
        all_predictions[img_id] = predictions
        all_gt[img_id] = annotations.get(img_id, [])
        processed += 1
    
    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–∏ —Ä–∞–∑–Ω—ã—Ö IoU
    print(f"\nüìä –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫...")
    
    # IoU thresholds –¥–ª—è mAP@50:95
    iou_thresholds = np.arange(0.5, 1.0, 0.05)  # [0.5, 0.55, 0.6, ..., 0.95]
    
    # mAP@50
    results_50 = evaluate_at_iou(all_predictions, all_gt, 0.5)
    
    # mAP –ø—Ä–∏ –∫–∞–∂–¥–æ–º IoU –¥–ª—è mAP@50:95
    ap_per_iou = []
    for iou_th in iou_thresholds:
        results_iou = evaluate_at_iou(all_predictions, all_gt, iou_th)
        mean_ap = np.mean([r['ap'] for r in results_iou.values()])
        ap_per_iou.append(mean_ap)
    
    # –ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    mAP50 = np.mean([r['ap'] for r in results_50.values()])
    mAP50_95 = np.mean(ap_per_iou)
    mAR50 = np.mean([r['recall'] for r in results_50.values()])
    
    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\n" + "=" * 70)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û –ö–õ–ê–°–°–ê–ú (IoU=0.5)")
    print("=" * 70)
    
    print(f"\n{'–ö–ª–∞—Å—Å':<12} {'AP@50':>10} {'Recall':>10} {'Precision':>10} {'TP':>8} {'FP':>8} {'FN':>8}")
    print("-" * 70)
    
    total_tp, total_fp, total_fn = 0, 0, 0
    total_gt, total_pred = 0, 0
    
    for cls in GARBAGE_CLASSES:
        r = results_50[cls]
        print(f"{cls:<12} {r['ap']:>10.4f} {r['recall']:>10.4f} {r['precision']:>10.4f} {r['tp']:>8} {r['fp']:>8} {r['fn']:>8}")
        total_tp += r['tp']
        total_fp += r['fp']
        total_fn += r['fn']
        total_gt += r['total_gt']
        total_pred += r['total_pred']
    
    print("-" * 70)
    overall_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0
    overall_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0
    print(f"{'OVERALL':<12} {mAP50:>10.4f} {overall_recall:>10.4f} {overall_precision:>10.4f} {total_tp:>8} {total_fp:>8} {total_fn:>8}")
    
    # mAP@50:95 –ø–æ IoU
    print(f"\n{'='*70}")
    print("üìä AP –ü–û –†–ê–ó–ù–´–ú IoU THRESHOLDS")
    print("=" * 70)
    print(f"\n{'IoU':>8}", end="")
    for cls in GARBAGE_CLASSES:
        print(f"{cls[:6]:>10}", end="")
    print(f"{'mAP':>10}")
    print("-" * 70)
    
    for i, iou_th in enumerate(iou_thresholds):
        results_iou = evaluate_at_iou(all_predictions, all_gt, iou_th)
        print(f"{iou_th:>8.2f}", end="")
        for cls in GARBAGE_CLASSES:
            print(f"{results_iou[cls]['ap']:>10.4f}", end="")
        print(f"{ap_per_iou[i]:>10.4f}")
    
    # –ì–ª–∞–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    print("\n" + "=" * 70)
    print("üèÜ –ì–õ–ê–í–ù–´–ï –ú–ï–¢–†–ò–ö–ò")
    print("=" * 70)
    print(f"\n   üìä mAP@50:        {mAP50:.4f}")
    print(f"   üìä mAP@50:95:     {mAP50_95:.4f}")
    print(f"   üìä mAR@50:        {mAR50:.4f}")
    print()
    print(f"   üìà Precision@50:  {overall_precision:.4f}")
    print(f"   üìà Recall@50:     {overall_recall:.4f}")
    print(f"   üìà F1@50:         {2*overall_precision*overall_recall/(overall_precision+overall_recall) if (overall_precision+overall_recall) > 0 else 0:.4f}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print(f"   ‚Ä¢ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:    {processed}")
    print(f"   ‚Ä¢ GT –æ–±—ä–µ–∫—Ç–æ–≤:    {total_gt}")
    print(f"   ‚Ä¢ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:   {total_pred}")
    print(f"   ‚Ä¢ True Positives: {total_tp}")
    print(f"   ‚Ä¢ False Positives:{total_fp}")
    print(f"   ‚Ä¢ False Negatives:{total_fn}")
    
    # –í—Ä–µ–º—è
    print(f"\n‚è±Ô∏è –í–†–ï–ú–Ø –ò–ù–§–ï–†–ï–ù–°–ê")
    print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ:        {np.mean(inference_times)*1000:.1f} ms")
    print(f"   ‚Ä¢ –ú–µ–¥–∏–∞–Ω–∞:        {np.median(inference_times)*1000:.1f} ms")
    print(f"   ‚Ä¢ FPS:            {1/np.mean(inference_times):.1f}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if save_results:
        results_data = {
            'config': {
                'dataset': dataset_dir,
                'split': split,
                'conf_threshold': conf_threshold,
                'yolo_path': yolo_path,
                'detr_path': detr_path
            },
            'metrics': {
                'mAP50': float(mAP50),
                'mAP50_95': float(mAP50_95),
                'mAR50': float(mAR50),
                'precision': float(overall_precision),
                'recall': float(overall_recall),
                'f1': float(2*overall_precision*overall_recall/(overall_precision+overall_recall) if (overall_precision+overall_recall) > 0 else 0)
            },
            'per_class_AP50': {cls: float(results_50[cls]['ap']) for cls in GARBAGE_CLASSES},
            'per_class_AR50': {cls: float(results_50[cls]['recall']) for cls in GARBAGE_CLASSES},
            'ap_per_iou': {f"IoU_{iou:.2f}": float(ap) for iou, ap in zip(iou_thresholds, ap_per_iou)},
            'counts': {
                'images': processed,
                'total_gt': total_gt,
                'total_pred': total_pred,
                'tp': total_tp,
                'fp': total_fp,
                'fn': total_fn
            },
            'timing': {
                'avg_ms': float(np.mean(inference_times) * 1000),
                'median_ms': float(np.median(inference_times) * 1000),
                'fps': float(1 / np.mean(inference_times))
            }
        }
        
        output_file = f"ensemble_test_results_{split}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, indent=2, ensure_ascii=False)
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_file}")
    
    print("\n" + "=" * 70)
    
    return {
        'mAP50': mAP50,
        'mAP50_95': mAP50_95,
        'mAR50': mAR50
    }


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–≤")
    parser.add_argument("--dataset", type=str, default="data/complete_dataset",
                        help="–ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É")
    parser.add_argument("--split", type=str, default="test", choices=["train", "valid", "test"],
                        help="–ö–∞–∫–æ–π split —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å")
    parser.add_argument("--yolo", type=str, default="models/yolo/yolov8x/best.pt",
                        help="–ü—É—Ç—å –∫ YOLO –º–æ–¥–µ–ª–∏")
    parser.add_argument("--detr", type=str, default="models/rt-detr/rt-detr-101/m",
                        help="–ü—É—Ç—å –∫ RT-DETR –º–æ–¥–µ–ª–∏")
    parser.add_argument("--detr_processor", type=str, default="models/rt-detr/rt-detr-101/p",
                        help="–ü—É—Ç—å –∫ RT-DETR –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—É")
    parser.add_argument("--conf", type=float, default=0.01,
                        help="–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (–Ω–∏–∑–∫–∏–π –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ AP)")
    parser.add_argument("--no_save", action="store_true",
                        help="–ù–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
    
    args = parser.parse_args()
    
    test_ensemble(
        dataset_dir=args.dataset,
        split=args.split,
        yolo_path=args.yolo,
        detr_path=args.detr,
        detr_processor_path=args.detr_processor,
        conf_threshold=args.conf,
        save_results=not args.no_save
    )
