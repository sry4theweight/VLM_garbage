"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ Roboflow –¥–ª—è –æ–±—É—á–µ–Ω–∏—è VLM
"""

import argparse
import json
import random
from pathlib import Path
from vlm_annotation.data_annotation import VLMDataAnnotator
from vlm_annotation.ensemble_detector import EnsembleDetector


def collect_all_images(dataset_path: Path, image_extensions: list = None, 
                       skip_augmented: bool = True) -> list:
    """
    –°–æ–±—Ä–∞—Ç—å –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞
    
    Args:
        dataset_path: –ø—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É
        image_extensions: —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤
        skip_augmented: –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø–∞–ø–∫—É train (—Å–æ–¥–µ—Ä–∂–∏—Ç –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
    """
    if image_extensions is None:
        image_extensions = ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']
    
    all_images = []
    
    # –ï—Å–ª–∏ skip_augmented=True, –±–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ valid –∏ test (–±–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π)
    # train –≤ Roboflow –æ–±—ã—á–Ω–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–ø–∏–∏
    if skip_augmented:
        subdirs = ['valid', 'test']
        print("üìå –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ valid –∏ test (–±–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π)")
    else:
        subdirs = ['train', 'valid', 'test']
    
    for subdir in subdirs:
        subdir_path = dataset_path / subdir
        if subdir_path.exists():
            count = 0
            for f in subdir_path.iterdir():
                if f.suffix in image_extensions:
                    all_images.append(f)
                    count += 1
            print(f"   {subdir}: {count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∫–æ—Ä–Ω–µ
    for f in dataset_path.iterdir():
        if f.is_file() and f.suffix in image_extensions:
            all_images.append(f)
    
    return all_images


def annotate_roboflow_dataset(
    roboflow_dataset_dir: str,
    output_dir: str,
    yolo_model: str,
    detr_model: str,
    detr_processor: str,
    llm_model: str = "Salesforce/blip-image-captioning-large",
    conf_threshold: float = 0.6,
    max_images: int = None,
    seed: int = 42,
    skip_augmented: bool = True
):
    """
    –†–∞–∑–º–µ—Ç–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ Roboflow (–≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª)
    
    Args:
        roboflow_dataset_dir: –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ Roboflow
        output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ç–∫–∏
        yolo_model: –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ YOLO
        detr_model: –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ RT-DETR
        detr_processor: –ø—É—Ç—å –∫ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—É RT-DETR
        llm_model: –º–æ–¥–µ–ª—å LLM –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø–∏—Å–∞–Ω–∏–π
        conf_threshold: –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.6)
        max_images: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (None = –≤—Å–µ)
        seed: seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞
        skip_augmented: –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å train (–∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
    """
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    random.seed(seed)
    
    dataset_path = Path(roboflow_dataset_dir)
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # –°–æ–±–∏—Ä–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –±–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑ train)
    print("Collecting images from dataset...")
    all_images = collect_all_images(dataset_path, skip_augmented=skip_augmented)
    print(f"Found {len(all_images)} images total")
    
    # –°–ª—É—á–∞–π–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if max_images is not None and max_images < len(all_images):
        all_images = random.sample(all_images, max_images)
        print(f"Randomly selected {max_images} images for annotation")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
    print("\nInitializing ensemble detector...")
    detector = EnsembleDetector(
        yolo_model_path=yolo_model,
        detr_model_path=detr_model,
        detr_processor_path=detr_processor,
        conf_threshold=conf_threshold
    )
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ç–æ—Ä–∞
    print("Initializing VLM data annotator...")
    annotator = VLMDataAnnotator(
        ensemble_detector=detector,
        llm_model_name=llm_model
    )
    
    print(f"\n{'='*60}")
    print(f"Processing {len(all_images)} images...")
    print(f"{'='*60}")
    
    # –ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    output_file = output_path / "annotations.json"
    annotator.annotate_images(all_images, str(output_file))
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–∞–∑–º–µ—Ç–∫–µ
    info = {
        "dataset_path": str(dataset_path),
        "output_dir": str(output_path),
        "output_file": str(output_file),
        "total_images": len(all_images),
        "model_config": {
            "yolo_model": yolo_model,
            "detr_model": detr_model,
            "detr_processor": detr_processor,
            "llm_model": llm_model,
            "conf_threshold": conf_threshold,
            "max_images": max_images
        }
    }
    
    info_file = output_path / "annotation_info.json"
    with open(info_file, 'w', encoding='utf-8') as f:
        json.dump(info, f, indent=2, ensure_ascii=False)
    
    print(f"\n{'='*60}")
    print("Annotation completed!")
    print(f"Annotations saved to: {output_file}")
    print(f"Info saved to: {info_file}")
    print(f"{'='*60}")
    
    return str(output_file)


def main():
    parser = argparse.ArgumentParser(description="–†–∞–∑–º–µ—Ç–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ Roboflow –¥–ª—è –æ–±—É—á–µ–Ω–∏—è VLM")
    parser.add_argument(
        "--roboflow_dataset_dir",
        type=str,
        default="data/roboflow_dataset",
        help="–ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ Roboflow"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="data/vlm_annotations",
        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ç–∫–∏"
    )
    parser.add_argument(
        "--yolo_model",
        type=str,
        default="models/yolo/yolov8x/best.pt",
        help="–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ YOLO"
    )
    parser.add_argument(
        "--detr_model",
        type=str,
        default="models/rt-detr/rt-detr-101/m",
        help="–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ RT-DETR (–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è m/)"
    )
    parser.add_argument(
        "--detr_processor",
        type=str,
        default="models/rt-detr/rt-detr-101/p",
        help="–ü—É—Ç—å –∫ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—É RT-DETR (–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è p/)"
    )
    parser.add_argument(
        "--llm_model",
        type=str,
        default="Salesforce/blip-image-captioning-large",
        help="–ù–∞–∑–≤–∞–Ω–∏–µ LLM –º–æ–¥–µ–ª–∏ –∏–∑ HuggingFace"
    )
    parser.add_argument(
        "--conf_threshold",
        type=float,
        default=0.6,
        help="–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.6)"
    )
    parser.add_argument(
        "--max_images",
        type=int,
        default=200,
        help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 200)"
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"
    )
    parser.add_argument(
        "--include_train",
        action="store_true",
        help="–í–∫–ª—é—á–∏—Ç—å –ø–∞–ø–∫—É train (—Å–æ–¥–µ—Ä–∂–∏—Ç –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ valid/test."
    )
    
    args = parser.parse_args()
    
    annotate_roboflow_dataset(
        roboflow_dataset_dir=args.roboflow_dataset_dir,
        output_dir=args.output_dir,
        yolo_model=args.yolo_model,
        detr_model=args.detr_model,
        detr_processor=args.detr_processor,
        llm_model=args.llm_model,
        skip_augmented=not args.include_train,
        conf_threshold=args.conf_threshold,
        max_images=args.max_images,
        seed=args.seed
    )


if __name__ == "__main__":
    main()

