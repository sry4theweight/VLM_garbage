"""
–û–±—É—á–µ–Ω–∏–µ YOLOv8 –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å—Ü–µ–Ω (terrain)

–ö–ª–∞—Å—Å—ã: grass, marshy, rocky, sandy

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python train_scene_yolo.py --epochs 50
"""

import os
import shutil
from pathlib import Path
import argparse
from ultralytics import YOLO
import yaml


# –ö–ª–∞—Å—Å—ã —Å—Ü–µ–Ω
SCENE_CLASSES = ['grass', 'marshy', 'rocky', 'sandy']


def prepare_dataset_for_yolo(
    source_dir: str = "data/scene_dataset",
    output_dir: str = "data/scene_yolo_dataset"
):
    """
    –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YOLO classification
    
    YOLO classification –æ–∂–∏–¥–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É:
    dataset/
        train/
            class1/
                img1.jpg
            class2/
                img2.jpg
        val/
            class1/
            class2/
    """
    source_dir = Path(source_dir)
    output_dir = Path(output_dir)
    
    # –û—á–∏—â–∞–µ–º output –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    if output_dir.exists():
        shutil.rmtree(output_dir)
    
    # –°–æ–∑–¥–∞—ë–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    for split in ['train', 'val']:
        for cls in SCENE_CLASSES:
            (output_dir / split / cls).mkdir(parents=True, exist_ok=True)
    
    # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
    total_copied = 0
    
    for split in ['train', 'val']:
        source_split = source_dir / split
        if not source_split.exists():
            print(f"‚ö†Ô∏è –ü–∞–ø–∫–∞ {source_split} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            continue
            
        for cls in SCENE_CLASSES:
            source_cls = source_split / cls
            if not source_cls.exists():
                continue
                
            dest_cls = output_dir / split / cls
            
            for img_path in list(source_cls.glob("*.jpg")) + list(source_cls.glob("*.png")):
                shutil.copy(img_path, dest_cls / img_path.name)
                total_copied += 1
    
    print(f"‚úÖ –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ {total_copied} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ {output_dir}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
    for split in ['train', 'val']:
        print(f"\n{split}:")
        for cls in SCENE_CLASSES:
            count = len(list((output_dir / split / cls).glob("*")))
            print(f"  {cls}: {count}")
    
    return str(output_dir)


def check_gpu():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ GPU"""
    import torch
    
    print("\n" + "=" * 60)
    print("–ü–†–û–í–ï–†–ö–ê GPU")
    print("=" * 60)
    
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        print(f"‚úÖ CUDA –¥–æ—Å—Ç—É–ø–Ω–∞! GPU: {gpu_count}")
        
        for i in range(gpu_count):
            props = torch.cuda.get_device_properties(i)
            total_mem = props.total_memory / 1024**3
            print(f"   GPU {i}: {props.name}")
            print(f"   ‚Ä¢ –ü–∞–º—è—Ç—å: {total_mem:.1f} GB")
            print(f"   ‚Ä¢ Compute Capability: {props.major}.{props.minor}")
        
        # –û—á–∏—â–∞–µ–º –∫—ç—à
        torch.cuda.empty_cache()
        
        return 0  # device index
    else:
        print("‚ùå CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞! –û–±—É—á–µ–Ω–∏–µ –Ω–∞ CPU –±—É–¥–µ—Ç –º–µ–¥–ª–µ–Ω–Ω—ã–º.")
        return 'cpu'


def train_scene_classifier_yolo(
    data_dir: str = "data/scene_yolo_dataset",
    model_name: str = "yolov8x-cls",  # EXTRA-LARGE classification model
    epochs: int = 50,
    imgsz: int = 640,  # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
    batch: int = 64,   # –ë–æ–ª—å—à–æ–π batch –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    output_dir: str = "models/scene_yolo"
):
    """
    –û–±—É—á–µ–Ω–∏–µ YOLOv8 –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Å—Ü–µ–Ω
    
    Args:
        data_dir: –ø—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ YOLO classification
        model_name: –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (yolov8n-cls, yolov8s-cls, yolov8m-cls, yolov8l-cls, yolov8x-cls)
        epochs: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
        imgsz: —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        batch: —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
        output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
    """
    import torch
    
    print("\n" + "=" * 60)
    print("–û–ë–£–ß–ï–ù–ò–ï YOLO –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–†–ê –°–¶–ï–ù")
    print("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º GPU
    device = check_gpu()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    data_dir = Path(data_dir)
    if not data_dir.exists():
        print(f"\n‚ùå –î–∞—Ç–∞—Å–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {data_dir}")
        print("   –°–Ω–∞—á–∞–ª–∞ —Å–∫–∞—á–∞–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç:")
        print("   python download_scene_dataset.py --download")
        return None
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    train_dir = data_dir / "train"
    has_images = False
    if train_dir.exists():
        for cls_dir in train_dir.iterdir():
            if cls_dir.is_dir() and list(cls_dir.glob("*"))[:1]:
                has_images = True
                break
    
    if not has_images:
        print(f"\n‚ùå –ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ {train_dir}")
        print("   –°–Ω–∞—á–∞–ª–∞ —Å–∫–∞—á–∞–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç:")
        print("   python download_scene_dataset.py --download")
        return None
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    print(f"\nüì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {model_name}")
    model = YOLO(f"{model_name}.pt")
    
    # –û–±—É—á–µ–Ω–∏–µ —Å —è–≤–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º GPU
    print(f"\nüöÄ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è...")
    print(f"   –î–∞—Ç–∞—Å–µ—Ç: {data_dir}")
    print(f"   –ú–æ–¥–µ–ª—å: {model_name} (EXTRA-LARGE)")
    print(f"   –≠–ø–æ—Ö: {epochs}")
    print(f"   –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {imgsz}")
    print(f"   Batch size: {batch}")
    print(f"   Device: {'GPU' if device == 0 else device}")
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ GPU
    results = model.train(
        data=str(data_dir),
        epochs=epochs,
        imgsz=imgsz,
        batch=batch,
        project=output_dir,
        name="scene_classifier",
        exist_ok=True,
        patience=10,
        save=True,
        plots=True,
        verbose=True,
        device=device,           # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º GPU
        workers=8,               # –ë–æ–ª—å—à–µ workers –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        amp=True,                # Mixed precision –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        cache=True,              # –ö—ç—à–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ RAM/GPU
        optimizer='AdamW',       # –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
        lr0=0.001,               # Learning rate
        lrf=0.01,                # Final LR ratio
        warmup_epochs=3,         # Warmup
        cos_lr=True,             # Cosine LR scheduler
        label_smoothing=0.1,     # –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
    )
    
    # –ö–æ–ø–∏—Ä—É–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
    best_model_path = Path(output_dir) / "scene_classifier" / "weights" / "best.pt"
    final_model_path = Path("models") / "scene_classifier_yolo.pt"
    
    if best_model_path.exists():
        shutil.copy(best_model_path, final_model_path)
        print(f"\n‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {final_model_path}")
    
    return results


class SceneClassifierYOLO:
    """–ò–Ω—Ñ–µ—Ä–µ–Ω—Å YOLO –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Å—Ü–µ–Ω"""
    
    def __init__(self, model_path: str = "models/scene_classifier_yolo.pt"):
        from ultralytics import YOLO
        
        print(f"Loading YOLO scene classifier from {model_path}...")
        self.model = YOLO(model_path)
        self.classes = SCENE_CLASSES
        print(f"‚úÖ –ö–ª–∞—Å—Å—ã: {self.classes}")
    
    def predict(self, image):
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞ —Å—Ü–µ–Ω—ã
        
        Args:
            image: –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –∏–ª–∏ PIL Image
            
        Returns:
            dict —Å 'class', 'confidence', 'all_probs'
        """
        results = self.model(image, verbose=False)
        
        probs = results[0].probs
        top1_idx = probs.top1
        top1_conf = probs.top1conf.item()
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        all_probs = {}
        for i, cls in enumerate(self.classes):
            if i < len(probs.data):
                all_probs[cls] = probs.data[i].item()
            else:
                all_probs[cls] = 0.0
        
        return {
            'class': self.classes[top1_idx] if top1_idx < len(self.classes) else 'unknown',
            'confidence': top1_conf,
            'all_probs': all_probs
        }


def test_classifier(model_path: str, test_dir: str = "data/scene_yolo_dataset/val"):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞"""
    print("\n" + "=" * 60)
    print("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–†–ê")
    print("=" * 60)
    
    classifier = SceneClassifierYOLO(model_path)
    
    test_dir = Path(test_dir)
    correct = 0
    total = 0
    
    for cls in SCENE_CLASSES:
        cls_dir = test_dir / cls
        if not cls_dir.exists():
            continue
            
        for img_path in list(cls_dir.glob("*.jpg"))[:10]:  # –¢–µ—Å—Ç –Ω–∞ 10 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
            pred = classifier.predict(str(img_path))
            is_correct = pred['class'] == cls
            correct += int(is_correct)
            total += 1
            
            status = "‚úÖ" if is_correct else "‚ùå"
            print(f"{status} {img_path.name}: {pred['class']} ({pred['confidence']:.2%}) [GT: {cls}]")
    
    if total > 0:
        print(f"\nüìä Accuracy: {correct}/{total} = {correct/total:.2%}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Train YOLO scene classifier")
    parser.add_argument("--prepare_only", action="store_true", help="Only prepare dataset")
    parser.add_argument("--source_dir", type=str, default="data/scene_dataset")
    parser.add_argument("--data_dir", type=str, default="data/scene_yolo_dataset")
    parser.add_argument("--model", type=str, default="yolov8x-cls", 
                        choices=["yolov8n-cls", "yolov8s-cls", "yolov8m-cls", "yolov8l-cls", "yolov8x-cls"],
                        help="–ú–æ–¥–µ–ª—å (x = —Å–∞–º–∞—è –±–æ–ª—å—à–∞—è –∏ —Ç–æ—á–Ω–∞—è)")
    parser.add_argument("--epochs", type=int, default=50)
    parser.add_argument("--batch", type=int, default=64, help="Batch size (–±–æ–ª—å—à–µ = –±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏)")
    parser.add_argument("--imgsz", type=int, default=640, help="–†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–±–æ–ª—å—à–µ = —Ç–æ—á–Ω–µ–µ)")
    parser.add_argument("--test", action="store_true", help="Test existing model")
    parser.add_argument("--model_path", type=str, default="models/scene_classifier_yolo.pt")
    
    args = parser.parse_args()
    
    if args.test:
        test_classifier(args.model_path, f"{args.data_dir}/val")
    elif args.prepare_only:
        prepare_dataset_for_yolo(args.source_dir, args.data_dir)
    else:
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
        prepare_dataset_for_yolo(args.source_dir, args.data_dir)
        
        # –û–±—É—á–µ–Ω–∏–µ
        train_scene_classifier_yolo(
            data_dir=args.data_dir,
            model_name=args.model,
            epochs=args.epochs,
            batch=args.batch,
            imgsz=args.imgsz
        )

